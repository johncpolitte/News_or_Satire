{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from scipy.sparse.linalg import norm, svds\n",
    "from scipy.sparse import csr_matrix, find\n",
    "from scipy.stats import beta\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the csv's that contain all of the articles and convert them into their corresponding dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df = pd.read_csv('data/cnn.csv')\n",
    "fox_df = pd.read_csv('data/fox.csv')\n",
    "onion_df = pd.read_csv('data/onion_csv.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the three dataframes into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The build_df function can be found in the df_builder_mini_cleaner.py file. It does a little bit of cleaning by removing some punctuation, turning all the uppercase letters to lowercase letters, and removes the (CNN) that is at the beginning of all of the CNN articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The build_df function also creates dummy variables for Satire, CNN, and Fox. It then takes 5000 CNN articles and 5000 Onion articles, and all of the Fox articles and puts them into one DataFrame with columns titled 'Article', 'Satire', 'CNN' and 'Fox'. Lastly it drops any articles that have less than 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = build_df(onion_df, fox_df, cnn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Satire</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washington in a statement confirming his suppo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington irked that the attorney general’s b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stamford ct lamenting that the numbers were mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nairobi kenya warning that a complete overhaul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>napa ca after being lovingly tended by generat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pineville la citing concerns over historically...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cambridge ma warning that nothing was more dan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south bend in stumbling through the restaurant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heaven speaking with obvious nostalgia regardi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cary nc competing to secure the new pet’s alle...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterbrook pa regaling a group of prospectiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>washington insisting that they had taken every...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>crystal river fl claiming he found the turn to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baghouz syria returning from the battlefield i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>washington shedding new light on efforts to co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>philadelphia saying he is always too embarrass...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>moreno valley ca kicking himself for focusing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>baghuz syria in an effort to track down and el...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>washington insisting that at no point in the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>moscow saying that he had been “totally blinds...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>st paul mn taken aback by the lack of question...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>washington exercising his powers of clemency f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>boulder co admitting he now felt “a bit foolis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>washington following the completion of the spe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>toledo oh delaying his usual afternoon session...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hoffman estates il in an effort to eliminate t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>new york shedding new light on the environment...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>new york in a move touted as a major victory f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>washington doubling down on his criticism of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>heathrow fl warning consumers of the hidden pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14324</th>\n",
       "      <td>ivanka the daughter of   donald trump was flyi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>donald trump on thursday abruptly called f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>trump has “less than a mandate” and is on a “s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>north carolina republican leaders are blasti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14328</th>\n",
       "      <td>the five suspects all in their early 20s were ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14329</th>\n",
       "      <td>german officials on thursday continued to hunt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>merkel encouraged companies to hire refugees  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>the new york times recently published an art...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>even in saudi arabia santa claus is coming t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>the un security council resolution was put for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>if adopted the treacherous resolution will gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>trump on friday released the dec 15 note fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14336</th>\n",
       "      <td>“it is almost exactly the model used by obama”...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>trump’s involvement in seeking changes early t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>both say they have lost jobs for missing days ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>fox news has exclusively obtained a letter bei...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>the islamic state terror group has released ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>fisher 60 was rushed to the hospital by los an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>thoughts and prayers for our friend and everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>like most news out of north korea a lot about ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344</th>\n",
       "      <td>the office of lawmaker lee cheol woo said form...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>their goal is to simplify a complicated tax co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14346</th>\n",
       "      <td>the united states on friday abstained from a u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>displaced when the islamic state group seized ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>it is unmistakably christmas on friday at the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>in the last week alone the obama administratio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>“his legacy is like one of those dolls that as...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>the incoming president announced saturday that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14352</th>\n",
       "      <td>miller a longtime spokesman for trump’s campai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>“we have rather ironclad information from sour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Satire  CNN  Fox\n",
       "0      washington in a statement confirming his suppo...       1    0    0\n",
       "1      washington irked that the attorney general’s b...       1    0    0\n",
       "2      stamford ct lamenting that the numbers were mu...       1    0    0\n",
       "3      nairobi kenya warning that a complete overhaul...       1    0    0\n",
       "4      napa ca after being lovingly tended by generat...       1    0    0\n",
       "5      pineville la citing concerns over historically...       1    0    0\n",
       "6      cambridge ma warning that nothing was more dan...       1    0    0\n",
       "7      south bend in stumbling through the restaurant...       1    0    0\n",
       "8      heaven speaking with obvious nostalgia regardi...       1    0    0\n",
       "9      cary nc competing to secure the new pet’s alle...       1    0    0\n",
       "10     chesterbrook pa regaling a group of prospectiv...       1    0    0\n",
       "11     washington insisting that they had taken every...       1    0    0\n",
       "12     crystal river fl claiming he found the turn to...       1    0    0\n",
       "13     baghouz syria returning from the battlefield i...       1    0    0\n",
       "14     washington shedding new light on efforts to co...       1    0    0\n",
       "15     philadelphia saying he is always too embarrass...       1    0    0\n",
       "16     moreno valley ca kicking himself for focusing ...       1    0    0\n",
       "17     baghuz syria in an effort to track down and el...       1    0    0\n",
       "18     washington insisting that at no point in the o...       1    0    0\n",
       "19     moscow saying that he had been “totally blinds...       1    0    0\n",
       "20     st paul mn taken aback by the lack of question...       1    0    0\n",
       "21     washington exercising his powers of clemency f...       1    0    0\n",
       "22     boulder co admitting he now felt “a bit foolis...       1    0    0\n",
       "23     washington following the completion of the spe...       1    0    0\n",
       "24     toledo oh delaying his usual afternoon session...       1    0    0\n",
       "25     hoffman estates il in an effort to eliminate t...       1    0    0\n",
       "26     new york shedding new light on the environment...       1    0    0\n",
       "27     new york in a move touted as a major victory f...       1    0    0\n",
       "28     washington doubling down on his criticism of t...       1    0    0\n",
       "29     heathrow fl warning consumers of the hidden pi...       1    0    0\n",
       "...                                                  ...     ...  ...  ...\n",
       "14324  ivanka the daughter of   donald trump was flyi...       0    0    1\n",
       "14325      donald trump on thursday abruptly called f...       0    0    1\n",
       "14326  trump has “less than a mandate” and is on a “s...       0    0    1\n",
       "14327    north carolina republican leaders are blasti...       0    0    1\n",
       "14328  the five suspects all in their early 20s were ...       0    0    1\n",
       "14329  german officials on thursday continued to hunt...       0    0    1\n",
       "14330  merkel encouraged companies to hire refugees  ...       0    0    1\n",
       "14331    the new york times recently published an art...       0    0    1\n",
       "14332    even in saudi arabia santa claus is coming t...       0    0    1\n",
       "14333  the un security council resolution was put for...       0    0    1\n",
       "14334  if adopted the treacherous resolution will gre...       0    0    1\n",
       "14335    trump on friday released the dec 15 note fro...       0    0    1\n",
       "14336  “it is almost exactly the model used by obama”...       0    0    1\n",
       "14337  trump’s involvement in seeking changes early t...       0    0    1\n",
       "14338  both say they have lost jobs for missing days ...       0    0    1\n",
       "14339  fox news has exclusively obtained a letter bei...       0    0    1\n",
       "14340    the islamic state terror group has released ...       0    0    1\n",
       "14341  fisher 60 was rushed to the hospital by los an...       0    0    1\n",
       "14342  thoughts and prayers for our friend and everyo...       0    0    1\n",
       "14343  like most news out of north korea a lot about ...       0    0    1\n",
       "14344  the office of lawmaker lee cheol woo said form...       0    0    1\n",
       "14345  their goal is to simplify a complicated tax co...       0    0    1\n",
       "14346  the united states on friday abstained from a u...       0    0    1\n",
       "14347  displaced when the islamic state group seized ...       0    0    1\n",
       "14348  it is unmistakably christmas on friday at the ...       0    0    1\n",
       "14349  in the last week alone the obama administratio...       0    0    1\n",
       "14350  “his legacy is like one of those dolls that as...       0    0    1\n",
       "14351  the incoming president announced saturday that...       0    0    1\n",
       "14352  miller a longtime spokesman for trump’s campai...       0    0    1\n",
       "14353  “we have rather ironclad information from sour...       0    0    1\n",
       "\n",
       "[14220 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Word Count for Each Article Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find the word count for each article I used the word_count function I wrote. It can be found in the word_counts.py file. These word counts were then put into a dataframe in order to be graphed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onion_word_count = word_count(list(df_final.Article[0:4927]))\n",
    "cnn_word_count = word_count(list(df_final.Article[4927:9927]))\n",
    "fox_word_count = word_count(list(df_final.Article[9927:]))\n",
    "word_counts_df = pd.DataFrame([['Onion', onion_word_count], ['CNN', cnn_word_count], ['Fox', fox_word_count]], columns=['Source', 'Average_Word_Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The word_count_graph function can also be found in the word_counts.py file. It converts the word_counts_df into a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_count_graph(word_counts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I wrote another cleaner function to eliminate unwanted characters and words that slipped through the cracks. Regular expression was used to select only characters in the alphabet, and remove 'fox' and 'news' from the corpus. The clean articles are inserted back into the dataframe and the dataframe is renamed to new_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_final = final_cleaner(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Satire</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>washington in a statement confirming his suppo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington irked that the attorney general s b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stamford ct lamenting that the numbers were mu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nairobi kenya warning that a complete overhaul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>napa ca after being lovingly tended by generat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pineville la citing concerns over historically...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cambridge ma warning that nothing was more dan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south bend in stumbling through the restaurant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heaven speaking with obvious nostalgia regardi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cary nc competing to secure the new pet s alle...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterbrook pa regaling a group of prospectiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>washington insisting that they had taken every...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>crystal river fl claiming he found the turn to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>baghouz syria returning from the battlefield i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>washington shedding new light on efforts to co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>philadelphia saying he is always too embarrass...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>moreno valley ca kicking himself for focusing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>baghuz syria in an effort to track down and el...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>washington insisting that at no point in the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>moscow saying that he had been totally blindsi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>st paul mn taken aback by the lack of question...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>washington exercising his powers of clemency f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>boulder co admitting he now felt a bit foolish...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>washington following the completion of the spe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>toledo oh delaying his usual afternoon session...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hoffman estates il in an effort to eliminate t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>new york shedding new light on the environment...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>new york in a move touted as a major victory f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>washington doubling down on his criticism of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>heathrow fl warning consumers of the hidden pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14324</th>\n",
       "      <td>ivanka the daughter of donald trump was flying...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>donald trump on thursday abruptly called for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>trump has less than a mandate and is on a shor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>north carolina republican leaders are blastin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14328</th>\n",
       "      <td>the five suspects all in their early s were ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14329</th>\n",
       "      <td>german officials on thursday continued to hunt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>merkel encouraged companies to hire refugees e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>the new york times recently published an arti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>even in saudi arabia santa claus is coming to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>the un security council resolution was put for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>if adopted the treacherous resolution will gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14335</th>\n",
       "      <td>trump on friday released the dec  note from p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14336</th>\n",
       "      <td>it is almost exactly the model used by obama ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>trump s involvement in seeking changes early t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>both say they have lost jobs for missing days ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>has exclusively obtained a letter being pres...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>the islamic state terror group has released a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>fisher  was rushed to the hospital by los ange...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>thoughts and prayers for our friend and everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14343</th>\n",
       "      <td>like most  out of north korea a lot about what...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344</th>\n",
       "      <td>the office of lawmaker lee cheol woo said form...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>their goal is to simplify a complicated tax co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14346</th>\n",
       "      <td>the united states on friday abstained from a u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>displaced when the islamic state group seized ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>it is unmistakably christmas on friday at the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>in the last week alone the obama administratio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>his legacy is like one of those dolls that as...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>the incoming president announced saturday that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14352</th>\n",
       "      <td>miller a longtime spokesman for trump s campai...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14353</th>\n",
       "      <td>we have rather ironclad information from sour...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14220 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Satire  CNN  Fox\n",
       "0      washington in a statement confirming his suppo...       1    0    0\n",
       "1      washington irked that the attorney general s b...       1    0    0\n",
       "2      stamford ct lamenting that the numbers were mu...       1    0    0\n",
       "3      nairobi kenya warning that a complete overhaul...       1    0    0\n",
       "4      napa ca after being lovingly tended by generat...       1    0    0\n",
       "5      pineville la citing concerns over historically...       1    0    0\n",
       "6      cambridge ma warning that nothing was more dan...       1    0    0\n",
       "7      south bend in stumbling through the restaurant...       1    0    0\n",
       "8      heaven speaking with obvious nostalgia regardi...       1    0    0\n",
       "9      cary nc competing to secure the new pet s alle...       1    0    0\n",
       "10     chesterbrook pa regaling a group of prospectiv...       1    0    0\n",
       "11     washington insisting that they had taken every...       1    0    0\n",
       "12     crystal river fl claiming he found the turn to...       1    0    0\n",
       "13     baghouz syria returning from the battlefield i...       1    0    0\n",
       "14     washington shedding new light on efforts to co...       1    0    0\n",
       "15     philadelphia saying he is always too embarrass...       1    0    0\n",
       "16     moreno valley ca kicking himself for focusing ...       1    0    0\n",
       "17     baghuz syria in an effort to track down and el...       1    0    0\n",
       "18     washington insisting that at no point in the o...       1    0    0\n",
       "19     moscow saying that he had been totally blindsi...       1    0    0\n",
       "20     st paul mn taken aback by the lack of question...       1    0    0\n",
       "21     washington exercising his powers of clemency f...       1    0    0\n",
       "22     boulder co admitting he now felt a bit foolish...       1    0    0\n",
       "23     washington following the completion of the spe...       1    0    0\n",
       "24     toledo oh delaying his usual afternoon session...       1    0    0\n",
       "25     hoffman estates il in an effort to eliminate t...       1    0    0\n",
       "26     new york shedding new light on the environment...       1    0    0\n",
       "27     new york in a move touted as a major victory f...       1    0    0\n",
       "28     washington doubling down on his criticism of t...       1    0    0\n",
       "29     heathrow fl warning consumers of the hidden pi...       1    0    0\n",
       "...                                                  ...     ...  ...  ...\n",
       "14324  ivanka the daughter of donald trump was flying...       0    0    1\n",
       "14325   donald trump on thursday abruptly called for ...       0    0    1\n",
       "14326  trump has less than a mandate and is on a shor...       0    0    1\n",
       "14327   north carolina republican leaders are blastin...       0    0    1\n",
       "14328  the five suspects all in their early s were ex...       0    0    1\n",
       "14329  german officials on thursday continued to hunt...       0    0    1\n",
       "14330  merkel encouraged companies to hire refugees e...       0    0    1\n",
       "14331   the new york times recently published an arti...       0    0    1\n",
       "14332   even in saudi arabia santa claus is coming to...       0    0    1\n",
       "14333  the un security council resolution was put for...       0    0    1\n",
       "14334  if adopted the treacherous resolution will gre...       0    0    1\n",
       "14335   trump on friday released the dec  note from p...       0    0    1\n",
       "14336   it is almost exactly the model used by obama ...       0    0    1\n",
       "14337  trump s involvement in seeking changes early t...       0    0    1\n",
       "14338  both say they have lost jobs for missing days ...       0    0    1\n",
       "14339    has exclusively obtained a letter being pres...       0    0    1\n",
       "14340   the islamic state terror group has released a...       0    0    1\n",
       "14341  fisher  was rushed to the hospital by los ange...       0    0    1\n",
       "14342  thoughts and prayers for our friend and everyo...       0    0    1\n",
       "14343  like most  out of north korea a lot about what...       0    0    1\n",
       "14344  the office of lawmaker lee cheol woo said form...       0    0    1\n",
       "14345  their goal is to simplify a complicated tax co...       0    0    1\n",
       "14346  the united states on friday abstained from a u...       0    0    1\n",
       "14347  displaced when the islamic state group seized ...       0    0    1\n",
       "14348  it is unmistakably christmas on friday at the ...       0    0    1\n",
       "14349  in the last week alone the obama administratio...       0    0    1\n",
       "14350   his legacy is like one of those dolls that as...       0    0    1\n",
       "14351  the incoming president announced saturday that...       0    0    1\n",
       "14352  miller a longtime spokesman for trump s campai...       0    0    1\n",
       "14353   we have rather ironclad information from sour...       0    0    1\n",
       "\n",
       "[14220 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A train, test split is used on the final dataframe for testing purposes. The docs_train and docs_test variables are the content of the articles, and the y_train, and y_test variables are the 'Satire' column, which indicates if the article is satirical or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(new_df_final['Article'], new_df_final['Satire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a list of the stopwords used for the tokenization process. All of these words are not included in the final word corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the tokenization function that is used in the TfidfVectorizor. It tokenizes all of the words in an article, removes all the words that are less than 1 character, removes the stop words, and finally stems each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search for min_df and max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df_gs = [0,1,3,5,10,15,50,100]\n",
    "max_df_gs = [1,.99,.95,.90,.75,.50,.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'min_df': min_df_gs, 'max_df': max_df_gs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gs = TfidfVectorizer(tokenizer=tokenize2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(vect_gs, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I vectorize the the articles using tfidf. A minimum term frequency of 3 and a maximum term frequency of 95% are used. The TfidfVectorizer also normalizes the tfidf. The training data is fit and transformed to the vectorizer to create X_train. The testing data is transformed into X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=main_tokenize)\n",
    "# tune min_df and use max_df\n",
    "X_train = vect.fit_transform(docs_train)\n",
    "X_test = vect.transform(docs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first model I used was a Logistic Regression model that could predict if the article was satirical or from a news source. The model was fit with the X_train data that had been vectorized, and the y_train data that is just a label that defines the article as being satire (1) or actual news (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jphooster22/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the testing data (X_test, y_test) and the fit model (log_reg), I made predictions for what class the articles are predicted to be in. I then used the confusion matrix to calculate the F1 score, Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_score(log_reg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for alpha\n",
    "\n",
    "na_ba_1 = MultinomialNB(alpha=1)\n",
    "na_ba_1.fit(X_train, y_train)\n",
    "\n",
    "na_ba = MultinomialNB(alpha=.1)\n",
    "na_ba.fit(X_train, y_train)\n",
    "\n",
    "na_ba_0 = MultinomialNB(alpha=.0001)\n",
    "na_ba_0.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_score(na_ba_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_score(na_ba, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_score(na_ba_0, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vis for Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciever Operating Characteristic Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the models above, I generated roc curves to show the diagnostic ability for the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_log_reg  = roc_curve(y_test, log_reg.predict_proba(X_test)[:,1], pos_label=1)\n",
    "\n",
    "roc_na_ba_1  = roc_curve(y_test, na_ba_1.predict_proba(X_test)[:,1], pos_label=1)\n",
    "roc_na_ba  = roc_curve(y_test, na_ba.predict_proba(X_test)[:,1], pos_label=1)\n",
    "roc_na_ba_0  = roc_curve(y_test, na_ba_0.predict_proba(X_test)[:,1], pos_label=1)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(roc_log_reg[0], roc_log_reg[1], color='darkorange',\n",
    "         lw=lw, label='Logistic Regression')\n",
    "\n",
    "plt.plot(roc_na_ba_1[0], roc_na_ba_1[1], color='b',\n",
    "         lw=lw, label='Naive Bayes, Alpha=1')\n",
    "plt.plot(roc_na_ba[0], roc_na_ba[1], color='c',\n",
    "         lw=lw, label='Naive Bayes, Alpha=0.1')\n",
    "plt.plot(roc_na_ba_0[0], roc_na_ba_0[1], color='r',\n",
    "         lw=lw, label='Naive Bayes, Alpha=0.0001')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ploted the confusion matrices for the Naive Bayes model and Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test,log_reg.predict(X_test)),['F','T'], title='Logistic Regression Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test,na_ba_1.predict(X_test)),['F','T'], title='Naive Bayes(alpha=1) Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test,na_ba.predict(X_test)),['F','T'], title='Naive Bayes(alpha=1) Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test,na_ba_0.predict(X_test)),['F','T'], title='Naive Bayes(alpha=1) Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is an investigation in to which words are the strongest indicators for an article being from the onion or Fox News and CNN. The higher the beta coeffecient the stronger the relationship that word has to being associated with an article from the onion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def high_low_beta_coef(vect_object, model_object):\n",
    "#     '''\n",
    "#     This function takes in a document frequency vector and a trained model object and generates a list \n",
    "#     of the words with the 10 highest and lowest beta coef. As an intermediary step a dataframe with \n",
    "#     all of the words in the vector and their corresponding beta coefficients. \n",
    "#     input:  \n",
    "#             vect_object = inverse document frequency vector ('vect')\n",
    "#             model_object = trained logistic regression model object ('log_reg')\n",
    "#     output: \n",
    "#             top_bot_words = list of the words that correspond to the 10 highest and 10 lowest beta coefficients \n",
    "#             bot_top_coef = list of the 10 lowest and highest beta coefficients\n",
    "#             sort = dataframe of the words in the vector space and their beta coefficients\n",
    "#     '''\n",
    "#     # Creates a data frame for each word and its corresponding\n",
    "#     features_df = pd.DataFrame(vect_object.get_feature_names())\n",
    "#     feature_df['Beta_Coef'] = model_object.coef_.reshape(model_object.coef_.shape[1],)\n",
    "#     feature_df['Word'] = feature_df[0]\n",
    "#     beta_feature_df = feature_df[['Beta_Coef', 'Word']]\n",
    "#     sort = beta_feature_df.sort_values('Beta_Coef')\n",
    "#     bot_top_coef = list(sort['Beta_Coef'][0:10]) + list(sort['Beta_Coef'][-10:])\n",
    "#     top_bot_words = list(sort['Word'][0:10]) + list(sort['Word'][-10:])\n",
    "#     return top_bot_words, bot_top_coef, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bot_words, bot_top_coef, sorted_BC_df = high_low_beta_coef(vect, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bot_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstemed_top_bot_words = ['said',\n",
    " 'trump',\n",
    " 'told',\n",
    " 'polic (police)',\n",
    " 'accord (according)',\n",
    " 'includ (include)',\n",
    " 'peopl (people)',\n",
    " 'twitter',\n",
    " 'saturday',\n",
    " 'clinton',\n",
    " 'note',\n",
    " 'just',\n",
    " 'washington',\n",
    " 'old',\n",
    " 'sourc (source)',\n",
    " 'confirm',\n",
    " 'time',\n",
    " 'press',\n",
    " 'reportedly (reportedli)',\n",
    " 'ad (added/adding)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bot_top_coef\n",
    "labels = top_bot_words\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "\n",
    "plt.bar(np.arange(len(data)), data, color = 'rrrrrrrrrrbbbbbbbbbb')\n",
    "ax.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=45, fontsize =20, ha='right', rotation_mode='anchor')\n",
    "plt.setp( ax.yaxis.get_majorticklabels(), fontsize = 20)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title(\"10 Largest and Smallest Beta Coef for Words\", fontsize = 20)\n",
    "ax.set_ylabel(\"Beta Coef Value\", fontsize = 20)\n",
    "ax.set_xlabel(\"Word\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing the Ad issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was worried about the word ad having such a high beta coefficient, and wanted to make sure the webscrapper for the onion was not scrapping advertisements. To address this issue I ran the the logistic regression model and vectorizor without using the stemmer, and compared the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_no_stemmer(doc):\n",
    "    '''\n",
    "    Tokenization function for the TFIDF vectorizor. This version of the tokenizer has no\n",
    "    stemming function\n",
    "    input: string of article\n",
    "    output: list of article tokens that have been stemmed\n",
    "    '''\n",
    "    # Tokenizes each word in the document\n",
    "    tokens = word_tokenize(doc)\n",
    "    # Defines an empty list to append the stemmed words to\n",
    "    cleaned_docs = []\n",
    "    # Creates PorterStemmer object\n",
    "    porter = PorterStemmer()\n",
    "    # For loop to iterate through tokens in document\n",
    "    for word in tokens:\n",
    "    # Removes tokens that are just one character\n",
    "        if len(word) < 2:\n",
    "            tokens.remove(word)\n",
    "    # Removes stop words from articles that are in test_stop_words \n",
    "    # list and appends porter stemmed words to the cleaned doc list\n",
    "        else:\n",
    "            if word not in test_stop_words:\n",
    "                    cleaned_docs.append(word)\n",
    "    # Returns list of tokens\n",
    "    return cleaned_docs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick test of what the stemmer does to 'add' and 'advertisement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "porter.stem('add'), porter.stem('adverstisement'), porter.stem('added'), porter.stem('adding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell I use the TfidfVectorizor to vectorize the corpus. For this example I did not use the porter stemmer. I fit and transformed the training data with the vectorizeor. A min_df of 3 was used and a max_df of 95% was used. I then transformed the testing data based on the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_no_stem = TfidfVectorizer(tokenizer=tokenize_no_stemmer, min_df=3, max_df=.95)\n",
    "# tune min_df and use max_df\n",
    "X_train_no_stem = vect_no_stem.fit_transform(docs_train)\n",
    "X_test_no_stem = vect_no_stem.transform(docs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I fit a logistic regression model used the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_no_stem = LogisticRegression()\n",
    "log_reg_no_stem.fit(X_train_no_stem, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bot_words_no_stem, bot_top_coef_no_stem, sorted_BC_df_no_stem = high_low_beta_coef(vect_no_stem, log_reg_no_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph of the words with the 10 largest and smallest beta coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bot_top_coef_no_stem\n",
    "labels = top_bot_words_no_stem\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "\n",
    "plt.bar(np.arange(len(data)), data, color = 'rrrrrrrrrrbbbbbbbbbb')\n",
    "ax.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=45, fontsize =20, ha='right', rotation_mode='anchor')\n",
    "plt.setp( ax.yaxis.get_majorticklabels(), fontsize = 20)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title(\"10 Largest and Smallest Beta Coef for Words (without stemming)\", fontsize = 20)\n",
    "ax.set_ylabel(\"Beta Coef Value\", fontsize = 20)\n",
    "ax.set_xlabel(\"Word\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results I can conclude that the word 'adding' is the one with a high beta coef and not some form of the word advertisement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Election Stop Word Removal Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_election = TfidfVectorizer(tokenizer=tokenize_election, min_df=3, max_df=.95)\n",
    "\n",
    "X_train_election = vect_election.fit_transform(docs_train)\n",
    "X_test_election = vect_election.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_election = LogisticRegression()\n",
    "log_reg_election.fit(X_train_election, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bot_words_election, bot_top_coef_election, sorted_BC_df_election = high_low_beta_coef(vect_election, log_reg_election)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bot_top_coef_election\n",
    "labels = top_bot_words_election\n",
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "\n",
    "plt.bar(np.arange(len(data)), data, color = 'rrrrrrrrrrbbbbbbbbbb')\n",
    "ax.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "plt.setp( ax.xaxis.get_majorticklabels(), rotation=45, fontsize =20, ha='right', rotation_mode='anchor')\n",
    "plt.setp( ax.yaxis.get_majorticklabels(), fontsize = 20)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title(\"10 Largest and Smallest Beta Coef for Words (election stopwords)\", fontsize = 20)\n",
    "ax.set_ylabel(\"Beta Coef Value\", fontsize = 20)\n",
    "ax.set_xlabel(\"Word\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Magnitude of TFIDF Vector for Satire and News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Satire_mag, News_mag = avg_tfidf_mag(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Satire_mag, News_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (8,8))\n",
    "plt.bar(['Satire', 'News'],[Satire_mag, News_mag], color ='rby')\n",
    "ax.set_title(\"Average Magnitude of Article Vector\", fontsize = 15)\n",
    "ax.set_ylabel(\"Magnitude\", fontsize = 15)\n",
    "ax.set_xlabel(\"Type of Article\", fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Trump Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'WASHINGTON—Following the announcement that Homeland Security Secretary Kirstjen Nielsen was leaving her post, President Trump told reporters Monday he would conduct an extensive search to find a replacement with the right personality disorders necessary for the role. “Though I admired Kirstjen’s ability to remain cold and detached when questioned about the decision to tear apart families at the border, we require someone with an even greater lack of empathy to do this job properly,” said the president, who praised Nielsen for putting children in cages but explained that the ideal candidate for the position must possess a degree of psychopathy so severe that they believe no law or moral code of any kind applies to them. “The next person to head the department must be blessed with strong narcissistic tendencies, of course, but also a consistent record of profoundly antisocial behavior. We need someone both spiteful and cruel, but also willing to totally disregard right and wrong. Basically, the new secretary will need to have a psychological makeup that allows them to look people in the eye and tell them, without hesitation, that we don’t want any non-Americans entering the United States unless they’re coming from one of a very limited group of countries in northern Europe.” At press time, a team of psychiatrists had reportedly presented the president with a stack of résumés that consisted solely of individuals housed in supermax prisons and White House senior adviser Stephen Miller.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def single_article_cleaner(single_article):\n",
    "#     '''\n",
    "#     Removes more features like punctuation and words that\n",
    "#     should not be in there\n",
    "#     Input: df_final\n",
    "#     output: df_final with cleaned articles\n",
    "#     '''\n",
    "#     clean_list = []\n",
    "#     samp = single_article.lower()\n",
    "#     samp1 = re.sub(r'\\W+', ' ', samp)\n",
    "#     samp2 = re.sub('[-—]', ' ', samp1)\n",
    "#     samp3 = samp2.replace('news','')\n",
    "#     clean_list.append(samp3.replace('fox',''))\n",
    "#     return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sample = single_article_cleaner(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['washington following the announcement that homeland security secretary kirstjen nielsen was leaving her post president trump told reporters monday he would conduct an extensive search to find a replacement with the right personality disorders necessary for the role though i admired kirstjen s ability to remain cold and detached when questioned about the decision to tear apart families at the border we require someone with an even greater lack of empathy to do this job properly said the president who praised nielsen for putting children in cages but explained that the ideal candidate for the position must possess a degree of psychopathy so severe that they believe no law or moral code of any kind applies to them the next person to head the department must be blessed with strong narcissistic tendencies of course but also a consistent record of profoundly antisocial behavior we need someone both spiteful and cruel but also willing to totally disregard right and wrong basically the new secretary will need to have a psychological makeup that allows them to look people in the eye and tell them without hesitation that we don t want any non americans entering the united states unless they re coming from one of a very limited group of countries in northern europe at press time a team of psychiatrists had reportedly presented the president with a stack of résumés that consisted solely of individuals housed in supermax prisons and white house senior adviser stephen miller ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_sample = vect.transform(clean_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx, col_idx, val = find(vect_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_col_list = list(zip(list(row_idx),(col_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_word_removal = []\n",
    "for idx in row_col_list:\n",
    "    vect_sample = vect.transform(clean_sample)\n",
    "    vect_sample[idx] = 0\n",
    "    prb = log_reg.predict_proba(vect_sample)\n",
    "    sat_prob = prb[0][1]\n",
    "    probas_word_removal.append(sat_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onion_prob_word_removal(vect_object, vect_sample):\n",
    "#     row_idx, col_idx, val = find(vect_sample)\n",
    "#     row_col_list = list(zip(list(row_idx),(col_idx)))\n",
    "#     feat_array = np.array(vect_object.get_feature_names())\n",
    "#     probas_word_removal = []\n",
    "#     for idx in row_col_list:\n",
    "#         vect_sample = vect_object.transform(clean_sample)\n",
    "#         vect_sample[idx] = 0\n",
    "#         prb = log_reg.predict_proba(vect_sample)\n",
    "#         sat_prob = prb[0][1]\n",
    "#         probas_word_removal.append(sat_prob)\n",
    "#     countmin = 0\n",
    "#     countmax = 0\n",
    "#     for x in probas_word_removal:\n",
    "#         if x == min(probas_word_removal):\n",
    "#             minword = countmin\n",
    "#         if x == max(probas_word_removal):\n",
    "#             maxword = countmax\n",
    "#         countmin += 1\n",
    "#         countmax += 1 \n",
    "#     return probas_word_removal,feat_array[col_idx[minword]], feat_array[col_idx[maxword]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onion_prob_word_removal(vect_object, clean_sample):\n",
    "    vect_sample = vect_object.transform(clean_sample)\n",
    "    row_idx, col_idx, val = find(vect_sample)\n",
    "    row_col_list = list(zip(list(row_idx),(col_idx)))\n",
    "    feat_array = np.array(vect_object.get_feature_names())\n",
    "    probas_word_removal = []\n",
    "    for idx in row_col_list:\n",
    "        vect_sample2 = vect_object.transform(clean_sample)\n",
    "        vect_sample2[idx] = 0\n",
    "        prb = log_reg.predict_proba(vect_sample2)\n",
    "        sat_prob = prb[0][1]\n",
    "        probas_word_removal.append(sat_prob)\n",
    "    countmin = 0\n",
    "    countmax = 0\n",
    "    for x in probas_word_removal:\n",
    "        if x == min(probas_word_removal):\n",
    "            minword = countmin\n",
    "        if x == max(probas_word_removal):\n",
    "            maxword = countmax\n",
    "        countmin += 1\n",
    "        countmax += 1\n",
    "    return probas_word_removal,feat_array[col_idx[minword]], feat_array[col_idx[maxword]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'vect_sample' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-73004d4f10a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobas_word_removal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monion_prob_word_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/galvanize/dsi/News_or_Satire/helper_functions.py\u001b[0m in \u001b[0;36monion_prob_word_removal\u001b[0;34m(vect_object, clean_sample)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monion_prob_word_removal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mrow_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0mrow_col_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mfeat_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'vect_sample' referenced before assignment"
     ]
    }
   ],
   "source": [
    "probas_word_removal, minword, maxword = onion_prob_word_removal(vect, clean_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.plot(probas_word_removal)\n",
    "ax.set_title(\"Prob of Being an Onion Article for Different Words Removed\", fontsize = 15)\n",
    "ax.set_ylabel(\"Prob of Onion\", fontsize = 15)\n",
    "ax.set_xlabel(\"Index for Word Removed\", fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(probas_word_removal), max(probas_word_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def max_min_proba(probas_word_removal):\n",
    "    countmin = 0\n",
    "    countmax = 0\n",
    "    for x in probas_word_removal:\n",
    "        if x == min(probas_word_removal):\n",
    "            test = countmin\n",
    "            print(countmin)\n",
    "            minword = countmin\n",
    "        if x == max(probas_word_removal):\n",
    "            test2 = countmax\n",
    "            print(countmax)\n",
    "            max_word = countmax\n",
    "        countmin += 1\n",
    "        countmax += 1\n",
    "    return test, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_proba(probas_word_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array[col_idx[81]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array[col_idx[104]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array[col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for half of a CNN article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_test ='Attorney General William Barr said Tuesday he expects to release a redacted version of special counsel Robert Muellers nearly report within a week, but he does not plan to provide Congress with an unredacted version of the report, setting the stage for a showdown with congressional Democrats.Barr told a House subcommittee Tuesday that the redactions process was going very well, and he would explain the rationale for the that are made from Muellers nearly 400-page report.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test ='Attorney General William Barr said Tuesday he expects to release a redacted version of special counsel Robert Muellers nearly report \"within a week,\" but he does not plan to provide Congress with an unredacted version of the report, setting the stage for a showdown with congressional Democrats.Barr told a House subcommittee Tuesday that the redactions process was going \"very well,\" and he would explain the rationale for the that are made from Muellers nearly 400-page report. But he said he would not accede to Democrats demands that he provide the full, unredacted report to Congress, arguing that he cannot legally release grand jury material and that he did not plan to ask a court to release it. \"I dont intend at this stage to send the full, unredacted report to the committee,\" Barr said.Barrs comments Tuesday come ahead of a brewing clash between Congress and the Trump administration over the Mueller report, as Democrats are indeed prepared to go to court in an effort to obtain the unredacted Mueller report and the special counsels underlying evidence. Democrats on the House Judiciary Committee have already authorized a subpoena for the full Mueller report and the underlying evidence, which House Judiciary Chairman Jerry Nadler said Tuesday he is waiting to see what Barr releases before moving forward on the subpoena. \"The question is what we receive -- do we receive a full copy of the Mueller Report and the documentation underneath it?\" Nadler said. \"Do we receive most of it with a little redaction or do they completely expurgate it? Well have to take a look at it.\" Asked Tuesday about the grand jury material, Barr told a House Appropriations subcommittee: \"The chairman of the Judiciary Committee is free to go to court.\" Four types of information would be redacted from the report he submits, Barr said, including grand jury material, classified information, material tied to ongoing investigation, and information that could harm \"peripheral third parties.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_test2 = 'report to the committee,\" Barr said.Barrs comments Tuesday come ahead of a brewing clash between Congress and the Trump administration over the Mueller report, as Democrats are indeed prepared to go to court in an effort to obtain the unredacted Mueller report and the special counsels underlying evidence. Democrats on the House Judiciary Committee have already authorized a subpoena for the full Mueller report and the underlying evidence, which House Judiciary Chairman Jerry Nadler said Tuesday he is waiting to see what Barr releases before moving forward on the subpoena. \"The question is what we receive -- do we receive a full copy of the Mueller Report and the documentation underneath it?\" Nadler said. \"Do we receive most of it with a little redaction or do they completely expurgate it? Well have to take a look at it.\" Asked Tuesday about the grand jury material, Barr told a House Appropriations subcommittee: \"The chairman of the Judiciary Committee is free to go to court.\" Four types of information would be redacted from the report he submits, Barr said, including grand jury material, classified information, material tied to ongoing investigation, and information that could harm \"peripheral third parties.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cnn_test2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_clean_sample = new_cleaner(cnn_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_vect_sample = vect.transform(cnn_clean_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_row, cnn_col, cnn_val = find(cnn_vect_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict_proba(cnn_vect_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict(cnn_vect_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array[cnn_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Cosine Sim between 100 CNN articles and 100 Onion articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions\n",
    "\n",
    "\n",
    "100 random vectors from onion and CNN\n",
    "cosine sim CNN CNN CNN onion\n",
    "cosine sim sqore for 100 of each \n",
    "\n",
    "\n",
    "Similarity in language in CNN vs onion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_arr = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_X_train= X_train[y_t_arr==1]\n",
    "news_X_train = X_train[y_t_arr==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_sat_X_train = sat_X_train[0:100]\n",
    "samp_news_X_train = news_X_train[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_news_X_train[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(samp_sat_X_train[0],samp_news_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_sims = cosine_similarity(samp_sat_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sims = cosine_similarity(samp_news_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_sims = cosine_similarity(samp_sat_X_train, samp_news_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_sims_tril = np.tril(sat_sims,-1)\n",
    "sat_sims_flat = sat_sims_tril.flatten()\n",
    "final_sat_sims = sat_sims_flat[sat_sims_flat != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_sat_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sims_tril = np.tril(news_sims,-1)\n",
    "news_sims_flat = news_sims_tril.flatten()\n",
    "final_news_sims = news_sims_flat[news_sims_flat != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combo_sims = combo_sims.flatten()\n",
    "len(final_combo_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_combo_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_sat_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(final_news_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "combo_hist =plt.hist(final_combo_sims, bins=200, range=(0,.5), label='Cosine Similarity Between News and Satire Articles', normed=True)\n",
    "sat_hist = plt.hist(final_sat_sims, bins=200, range=(0,.5), label='Cosine Similarity for Satirical Articles',normed=True)\n",
    "news_hist = plt.hist(final_news_sims, bins=200, range=(0,.5), label= 'Cosine Similarity for News Articles',normed=True)\n",
    "\n",
    "ax.set_title(\"Cosine Similarity Distribution Between News and Satire articles\", fontsize = 25)\n",
    "ax.set_ylabel(\"Count\", fontsize = 20)\n",
    "ax.set_xlabel(\"Cosine Similarity\", fontsize = 20)\n",
    "plt.legend(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snark_test = 'Aaron Rodgers went down with a leg injury during Week 1 of the 2018 season in the Packers’ Sunday Night Football game against the Chicago Bears in Green Bay. In a seemingly miraculous turn of events, Rodgers was able to return to the field in relief of backup QB DeShone Kiser who took for the Packers over after the injury, and lead the Packers to a comeback win. Though Rodgers was able to play out the year, we now know that the injury affected the Green Bay Packers quarterback throughout the entire 2018 season. Rodgers appeared on the “Wilde and Tausch” show of ESPN Wisconsin this week and revealed that he suffered not only a sprained MCL, but fractured his tibia in his leg leg during the 2nd quarter sack that caused the injury in that game against Chicago. “If you watch the hit back,” Rodgers said, “just my two bones are coming together on the outside, just kind of made an indent fracture. Very painful. The good thing was it’s not super weight bearing, like load bearing every single time. but there definitely was some movement and things you do naturally that affected it.” A tibial plateau fracture is a break of the upper part of the shinbone and takes months to recover from. For reference, J.J. Watt and Kobe Bryant have both suffered the same injury. Watt missed the entire rest of the season and Bryant missed months. “I really wasn’t 100 percent the entire year,” Rodgers noted during the interview. “I’m proud of the fact that I started 16 games. It’s disappointing how it ended.”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_snark = new_cleaner(snark_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snark_vect = vect.transform(clean_snark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict(snark_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict_proba(snark_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
