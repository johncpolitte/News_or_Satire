{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_df = pd.read_csv('data/cnn.csv')\n",
    "fox_df = pd.read_csv('data/fox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.capstone\n",
    "collection = db.onion1\n",
    "docs = collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onion_cleaner(mongo_cursor):\n",
    "    '''\n",
    "    input: mongo_cursor - cursor for the onion documents that \n",
    "    need cleaning\n",
    "    output: dataframe with articles cleaned and stripped of characters\n",
    "    Also adds Satire, CNN, and Fox columns for testing purposes\n",
    "    '''\n",
    "    dict_list = []\n",
    "    # for loop iterates through mongo cursor and removes '_id'dict\n",
    "    # it also breaks apart the dictionary into keys and values and \n",
    "    # appends to the dict_list\n",
    "    for x in mongo_cursor:\n",
    "        x.pop('_id')\n",
    "        q = list(x.items())\n",
    "        dict_list.append(q)\n",
    "    # Converts the dict_list to an array\n",
    "    art_arr = np.array(dict_list)\n",
    "    # Gets the shape of the array so it can be reshaped\n",
    "    art_shape = art_arr.shape\n",
    "    # Reshapes array so it is 2D\n",
    "    exp = art_arr.reshape(art_shape[0],art_shape[2])\n",
    "    # Creates DF with URL and Article columns\n",
    "    df = pd.DataFrame(exp, columns=['URL', 'Article'])\n",
    "    # Converts Article column to list for text processing\n",
    "    art = list(df['Article'])\n",
    "    clean_list = []\n",
    "    # Removes unwanted characters in article text and then appends\n",
    "    # to clean_list\n",
    "    for sample in art:\n",
    "        sample1 = re.sub('<br/>', '', sample)\n",
    "        sample2 = re.sub('</p>', '', sample1)\n",
    "        sample3 = re.sub('â€”', ' ', sample2)\n",
    "        sample4 = re.sub('<em>', '', sample3)\n",
    "        sample5 = re.sub('</em>', '', sample4)\n",
    "        sample6 = re.sub('\\xa0', '', sample5)\n",
    "        sample7 = re.sub('<p>', '', sample6)\n",
    "        sample8 = re.sub('sic', '', sample7)\n",
    "        clean_list.append(sample8)\n",
    "    # Adds cleaned articles back to DF\n",
    "    df['Article'] = clean_list\n",
    "    # Creates dummies columns for future testing\n",
    "    df['Satire'] = 1\n",
    "    df['CNN'] = 0\n",
    "    df['Fox']= 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fox_word_count(content_list):\n",
    "    '''\n",
    "    Takes in a list of fox articles that is a list of strings\n",
    "    and then returns an average word count for each article.\n",
    "    input: list of strings\n",
    "    output: average word count per article\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    words = 0\n",
    "    \n",
    "    \n",
    "    # Come back for more preprocessing\n",
    "    # Right now this is just a rough estimate\n",
    "    # because the numbers in the articles are messing up\n",
    "    # the count\n",
    "    # (), \"\" are also messing up the count\n",
    "    for x in content_list:\n",
    "        length = len(x.split()) \n",
    "        words += length\n",
    "        count += 1\n",
    "    print(count)\n",
    "    print(words)\n",
    "    return words/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(content_list):\n",
    "    '''\n",
    "    Takes in a list of fox articles that is a list of strings\n",
    "    and then returns an average word count for each article.\n",
    "    input: list of strings\n",
    "    output: average word count per article\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    words = 0\n",
    "    \n",
    "    \n",
    "    # Come back for more preprocessing\n",
    "    # Right now this is just a rough estimate\n",
    "    # because the numbers in the articles are messing up\n",
    "    # the count\n",
    "    # (), \"\" are also messing up the count\n",
    "    for x in content_list:\n",
    "        length = len(x.split()) \n",
    "        words += length\n",
    "        count += 1\n",
    "    print(count)\n",
    "    print(words)\n",
    "    return words/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_word_count(content_list):\n",
    "    '''\n",
    "    Takes in content of all cnn articles as a list. \n",
    "    Then removes the '(CNN)' that is at the beginning of every\n",
    "    article and gets a word count. \n",
    "    input: list of strings  \n",
    "    output: float - average number of words per article\n",
    "    '''\n",
    "    count = 0\n",
    "    words = 0\n",
    "    # Come back for more preprocessing\n",
    "    # Right now this is just a rough estimate\n",
    "    # because the numbers in the articles are messing up\n",
    "    # the count\n",
    "    # (), \"\" are also messing up the count\n",
    "    for article in content_list:\n",
    "        split_article = article.split()\n",
    "        for word in split_article:\n",
    "            if word == '(CNN)':\n",
    "                split_article.remove(word)\n",
    "        length = len(split_article) \n",
    "        words += length\n",
    "        count += 1\n",
    "    print(count)\n",
    "    print(words)\n",
    "    return words/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
